Ремарка. Пусть есть обучающий набор данных из 100 наблюдений (строк). За один проход обычный (_пакетный_) _градиентный спуск_ для того чтобы обновить веса модели _один раз_ будет использовать ==все 100 наблюдений обучающего набора==. _Стохастический градиентный спуск_ будет обновлять веса модели для каждого наблюдения в обучающем наборе данных (то есть 100 раз!). А мини-пакетный градиентный спуск с пакетом размера 5, будет обновлять веса модели на каждом пакете. В данному случае 20 раз (100 наблюдений / (5 наблюдений в пакете)). 

То есть другими словами, в случае пакетного градиентного спуска градиентны на каждой итерации обновления весов модели вычисляются с использованием всех экземпляров обучающего набора данных, в случае стохастического градиентного спуска -- с использованием одного случайно выбранного экземпляра, а в случае мини-пакетного градиентного спуска -- на базе мини-пакета случайных экземпляров.