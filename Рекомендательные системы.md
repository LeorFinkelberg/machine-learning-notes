### Колаборативная фильтрация

Если требуется предсказать рейтинг $r_{ij}$ фильма $j$ для пользователя $u_i$, который этот фильм не смотрел, то можно вычислить похожесть пользователя $u_i$ (similarity) и всех прочих пользователей в системе (или топ $k$ пользователей в системе), а затем посчитать среднее взвешенное рейтингов, взвешивая по похожести
$$
r_{ij} = \dfrac{\Sigma_k Similarites(u_i, u_k)}{\text{number of ratings}}.
$$
Однако, чтобы избавиться от смещения, можно оценку скорректировать
$$
r_{ij} = \bar{r}_i + \dfrac{\Sigma_k Similarities(u_i, u_k)\, (r_{kj} - \bar{r}_k)}{\text{number of raings}}.
$$
Похожесть можно оценить, например, с помощью _коэффициента корреляции Пирсона_, _косинусного расстояния_, _расстояния Жаккара_, _расстояния Хэмминга_ и пр.

Здесь предполагается, что пользователи похожи, если они взаимодействуют с сервисом похожим образом.

_Факторизация матриц_ -- метод декомпозиции исходной разреженной матрицы предпочтений (пользователь-итем) на низкоразмерные матирцы с латентными признаками. Преимущество этого подхода заключается в том, что даже если у двух пользователей нет явных или неявных оценок, мы можем определить похожесть по латентным признакам. 
$$
R \sim U \, P, \quad U \in R^{m \times k}, P \in R^{n \times k},
$$
где $k$ -- это ранг факторизации.

Требуется подобрать аппроксимацию таким образом, чтобы минимизровать следующую целевую функцию
$$
J = \| R - U \, P^T \|_2 + \lambda \big( \|U\|_2 + \|P\|_2\big).
$$
Первый компонент представляет собой среднеквадратическую ошибку расстояний между $R$ и ее аппроксимацией $U \, P^T$. Второй компонент -- это регуляризация для борьбы с переобучением. 

### Alternating Least Squares (ALS)

ALS -- это двухшаговый итерационный процесс. На каждой итерации сначала фиксируется матрица $P$ , а $U$ решается, затем $U$ фиксируется, а $P$ решается. Фиксируя матирцу $P$ и оптимизируя матрицу $U$ (и наоборот) мы по сути сводим задачу к задаче линейной регрессии.

Колаборативная фильтрация прекрасно подходит для рекомендательных систем, но когда в распоряжении имеется достаточное количество данных. Однако, важно помнить, что латентные (скрытые) признаки, которые мы получаем в рамках матричной декомпозиции не интерпретируются. Кроме того можно столкнуться с проблемой "холодного запуска". Если у нового продукта нет достаточного количества пользователей, модель не сможет рекомендовать новый продукт.

Ключевые параметры ALS в PySpark:
- `NumBlocks`: количество блоков пользователей и итемов, на которые разбивается матрица предпочтений для параллельной обработки.
- `rank`: число латентных признаков в модели. 
- `maxIter`: максимальное число итераций запуска.
- `regParam`: определяет параметр регуляризации.
- `implicitPrefs`: указывает следует ли использовать вариант явной обратной связи.
- `alpha`: этот параметр применяется к варианту ALS с неявной обратной связью и определяет базовую достоверность предпочтительных наблюдений.

Пример экземпляра
```python
from pyspark.ml.recommendation import ALS

als = ALS(
    rank=15,
    maxIter=2,
    regParam=0.01,
    userCol="userId",
    itemCol="movieId",
    ratingCol="rating",
    coldStartStrategy="drop",
    implicitPrefs=False,
)

model = als.fit(training)
predictions = model.transform(test)
evaluator = RegressionEvaluator(
	metricName="rmse",
	labelCol="rating",
	predictionCol="prediction",
)

rmse = evaluator.evaluate(predictions)

# Каждому пользователю рекомендуется 10 фильмов
userRecs = model.recommendForAllUseres(10)

# Каждому фильму рекомендуется 10 пользователей
movieRecs = model.recommendForAllItems(10)
```

