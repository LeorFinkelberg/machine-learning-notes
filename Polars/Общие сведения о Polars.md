Преимущества:
- Polars "из-коробки" поддерживает эффективное распараллеливание без дополнительной настройки.
- В Polars поддерживается модель памяти Apache Arrow.
- Потоковый интерфейс (Streaming API) позволяет обрабатывать результаты, не требуя, чтобы все данные находились в памяти.

Цель Polars сводится к следующему:
- эффективно утилизировать все доступные ядра процессора на машине,
- оптимизировать запросы,
- обрабатывать наборы данных, которые значительно превосходят доступную оперативную память.

Простой пример
```python
import polars as pl

q = pl.scan_csv("docs/data/iris.csv") \
    .filter(pl.col("sepal_length") > 5) \
    .group_by("species") \
    .agg(pl.all().sum())
			   
df = q.collect()
```

В Polars _нет индексов_ как в Pandas, поэтому выбрать целевые строки можно только с помощью методов фильтрации.

В PySpark, если требуется выбрать несколько строк, то можно воспользоваться методами `.where()` или `.filter()`
```python
# Если в исходном кадре данных не было столбца с ограничением уникальности, то его можно создать так
df = df.withColumn("id", F.monotonically_increasing_id())

# Выбираем 3-ю и 11-ую строки
df.where(F.col("id").isin([3, 11]))

# Выбираем все строки КРОМЕ 3-ей и 11-ой
df.where(~F.col("id").isin([3, 11]))
```

В Pandas мы поступили следующим образом
```python
# Выбираем 3-ю и 11-ую строки
df.iloc[[3, 11], :]

# Выбираем все строки КРОМЕ 3-ей и 11-ой
df.drop([3, 4])
```
