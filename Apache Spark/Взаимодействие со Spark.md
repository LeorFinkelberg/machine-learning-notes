Три способа взаимодействия со Spark:
- локальный режим (local mode) -- предпочитаемый разрботчиками, так как все работает на одном компьютере и не требует какой-либо специальной конфигурации.
- режим кластера (cluster mode) -- через диспетчер ресурсов, который развертывает приложение в кластере.
- интерактивный режим.

### Локальный режим

Локальный режим Spark позволяет работать всем компонентам Spark на одном компьютере, неважно, ноутбук это или сервер. Локальный режим позволяет вести разработку и отладку на одном компьютере.

Для запуска Spark в локальном режиме просто создается сеанс с указанием, что ведущий узел должен быть локальным
```python
spark = SparkSession \
    .builder \
    .appName("My application") \
	.master("local")  # ведущий узел локальный
    .getOrCreate()
```

### Режим кластера

В режиме кластера Spark превращается в систему с несколькими узлами -- с ведущим узлом и и рабочими узлами. Ведущий узел распределяет рабочую нагрузку по рабочим узлам, которые затем выполняют обработку. Цель кластера -- обеспечение большей вычислительной мощности, поскольку каждый (физический) узел представляет собой процессор, память и устройство хранения (при необходимости) в кластер.

Задание в кластере можно передать либо с помощью `spark-submit`, либо просто, указав URL ведущего узла Spark непосредственно в приложении.

### Интерактивный режим

Можно запустить Spark в полностью интерактивном режиме, который позволяет работать с большими данными в командной оболочке.

Для запуска интерактивного режима в локальном режиме следует перейти в каталог `bin` Spark и выполнить команду
```bash
$ ./spark-shell
```
Если имеется кластер, то можно задать URL ведущего узла кластера с использованием параметра `--master <Master's URL>`.
