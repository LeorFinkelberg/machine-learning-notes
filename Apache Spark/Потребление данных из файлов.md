Для больших данных широко используются новые форматы файлов (Avro, ORC, Parquet etc.), так как CSV или JSON уже не оправдывают ожиданий.

Для того чтобы в pandas прочитать CSV-файл, в котором в качестве кавычек используются символ `*` , в качестве разделителя -- символ `;`, а в столбце времени `releaseDate` (предполагается формат `m/d/Y`) есть пропуски, можно воспользоваться следующей конструкцией
```python
from datetime import datetime

# errors = "coerce" требуется для обработки случаев, когда pandas не может преобразовать значение во временную метку
date_parser = lambda date: pd.to_datetime(date, format="%m/%d/%Y", errors="coerce") 

df = pd.read_csv(
	"./books.csv",
	sep=";",
	quotechar="*",
	parse_dates=["releaseDate"],
	date_parser=date_parser,
	keep_default_na=False,  # чтобы не реагировал на пропуски (NaN) при парсинге даты
    infer_datetime_format=True,
)
```

Следует иметь в виду, что функция `pd.to_datetime()` для "старых" дат (скажем 1960 год) возвращает `NaT`. Например
```python
pd.to_datetime("05/09/1960", format="%m/%d/%Y", errors="coerce")  # Timestamp('1960-05-09 00:00:00')
# Но для 1660 года
pd.to_datetime("05/09/1660", format="%m/%d/%Y", errors="coerce")  # NaT 
```

К слову Polars такие временные метки обрабатывает корректно
```python
import polars as pl

df = pl.read_csv(
	"./books.csv",
	separator=";",
	quote_char="*",
	try_parse_dates=True,
).with_columns(
	pl.col("releaseDate").str.strptime(pl.Date, "%m/%d/%Y")  # -> date
)
```

Функция `datetime.strptime(x, <datetime_template>)` используется для парсинга временной метки, представленной в виде шаблона `<datetime_template>`. Для форматирования результата можно использовать метод `.strftime(<another_datetime_template>)`
```python
datetime.strptime("2024/05/09", "%Y/%m/%d").strftime("%d-%B-%Y")  # 09-May-2024 
```

В документации по параметру `keep_default_na` функции `pd.read_csv()` говорится, что если параметр `keep_default_na=False` и при этом параметр `na_values` не задан, то пропуски не будут рассматриваться парсером.

Если параметр `infer_datetime_format` выставлен в `True` и задан параметр `parse_dates`, то pandas будет пытаться вывести формат на основе данных столбца временных меток и выбрать более быстрый алгоритм парсинга. В некоторых случаях это позволяет увеличить скорость парсинга в 5-10 раз.

В Spark эту задачу можно решить так
```python
df = spark.read.format("csv") \
    .option("header", True) \
    .option("multiline", True) \
    .option("sep", ";") \
    .option("quote", ";") \
    .option("dateFormat", "MM/dd/yyyy") \  # подсказка как парсить дату
    .option("inferSchema", True) \
    .load("./books.csv")

df.printSchema()
root 
 |-- id: integer (nullable = true)
 |-- authorId: integer (nullable = true)
 |-- releaseDate: date (nullable = true)
 ...
```



