Spark поддерживает две стратегии внутрикласетрной коммуникации. При передаче данных от узла к узлу данные перетасовываются по всему кластеру. Существует три основных типа соединений:
- Sort Merge Join: для эффективного соединения данные должны быть равномерно распределены по соединяемым атрибутам.
- Broadcast Join: очень полезен при соединении маленькой таблицы и очень большой. Маленькая таблица транслируется на все рабочие узлы.
- Shuffle Hash Join: это соединение основывается на концепции MapReduce. Создание хеш-таблиц это дорогостоящая операция.

Рекомендуется использовать _Sort Merge Join_, когде требуется соединить _две большие таблицы_, и _Broadcast_ -- когда одна соединяемых таблиц _маленькая_ [[Литература#^ef7d57]]<p. 397>.

Также рекомендуется использовать UDF по минимуму.

Перетасовочные партиции (Shuffle Partitions) возникают при перетасовке данных для операций соединения и агрегации. При каждой перетасовке огромные массивы данных перемещаются между партициями. Пусть у нас есть небольшой набор данных с 8 партициями. Выполнив простой `groupBy` мы увеличиваем количество партиций до 200, так как это значение по умолчанию. Однако, есть возможность сбросить количество партиций следующей настройкой
```python
spark = SparkSession.builder.appName("...")\
    .master("local[*]") \
    .config("spark.sql.shuffle.partitions", 50) \  # <- NB!
    .getOrCreate()
```