В среде кластера имеется несколько отдельных компьютеров, и требуется, чтобы они работали единообразно. Диспетчеры ресурсов выполняют эту работу поверх операционных систем отдельных компьютеров. Для управления кластером обычно используется один диспетчер ресурсов.

Можно заменить эти физические компьютеры _виртуальными машинами_ или _контейнерами_. Использование этих технологий также является приемлемым решением, но виртуальными машинами и контейнерами необходимо управлять.

Необходимо убедиться в том, что Spark обеспечивает доступ к одному и тому же файлу на каждом узле, и позволить Spark выполнить всю трудоемкую работу (разделение файла на части и распределение).

Можно сделать файл доступным для всех узлов, используя распределенную файловую систему, сервис совместного использования файлов или совместно используемые накопители.
### Встроенный автономный режим управления ресурсами

Самый простой диспетчер ресурсов для изучения и использования встроен в Spark как _автономный диспетчер кластера_. 

_Рабочие узлы_ управляются _ведущим узлом_, который передает задачи в каждый исполнитель.

### YARN управляет ресурсами в среде Hadoop

YARN -- главный компонент развертывания Hadoop, он не является независимым компонентом. Если ваша организация уже работает с кластерами Hadoop, то наиболее вероятен запуск Apache Spark в том же (или смежном) кластере через YARN.

Диспетчер ресурсов YARN работает с диспетчером узлов YARN для управления исполнителями. Диспетчер ресурсов может быть объединен с диспетчером узлов HDFS при необходимости.

YARN предоставляет больше функциональных возможностей, чем Spark в автономном режиме в плане изоляции и управления приоритетами процессов, что может способствовать улучшению защиты и производительности.

### Mesos -- автономный диспетчер ресурсов

TODO

### Kubernetes управляет оркестровкой контейнеров

Для использования Kubernetes в Spark необходимо создать (или повторно использовать) контейнер Docker с установленным экземпляром Spark -- это является стандартным вариантом использования Kubernetes.

Kubernetes планирует операции с помощью своего планировщика и управляет обработкой через контейнеры. При использовании `spark-submit` планировщик Spark-on-Kubernetes создает контейнер Kubernetes, содержащий драйвер.

### Совместное использование файлов с помощью распределенных файловых систем

Распределенная файловая система (HDFS) позволяет совместно использовать файлы (или части файлов) на различных узлах для обеспечения доступа к ним и репликации данных.

HDFS предназначена для хранения больших файлов с использованием парадигмы "однократная запись, многократное чтение". Из-за этого _HDFS_ работает медленнее при записи или обновлении, но _оптимизирована для операций чтения_.

HDFS использует блоки для хранения информации. По умолчанию размер блока равен 128 Мб. HDFS не обеспечивает хорошую производительность, если необходимо обновлять данные, так как это файловая система, ориентированная на операции _чтения_.

Этот размер 128 Мб также означает, что если у вас имеется набор файлов с размером 32 Кб каждый, то это повлияет на производительность и физическое хранение: для каждого 32 Кб файла будет использовано 128 Мб на дисках.