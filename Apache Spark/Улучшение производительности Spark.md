Apache Spark предоставляет две различные методики повышения производительности:
- ==кеширование== с использованием методов `.cache()` и `.persist()`, которые могут _сохранять данные и генеалогию данных^[Генеалогия данных (data lineage) -- происхождение данных. В контексте Spark генеалогия данных представлена ориентированным ациклическим графом]_,
- ==механизм копирования данных в контрольных точках== (checkpointing) с использованием метода `.checkpoint()` для сохранения _только данных без их генеалогии_.

В контексте Spark генеалогия данных -- это и есть ориентированный ациклический граф (DAG).
### Кеширование

Кеширование можно использовать для повышения производительности. При кешировании содержимое кадра данных сохраняется в памяти или на диске или используется совокупность памяти и диска. При кэшировании также сохраняется генеалогия данных.

_Сохранение генеалогии данных_ полезно, только если необходимо восстанавливать набор данных с нуля, а это случается, когда _происходит критический сбой_ в работе одного из узлов кластера.

Spark предоставляет два метода кеширования: `.cache()` и `.persist()`. Они работают почти одинаково, но `.persist()`  позволяет определить применяемый уровень кеширования. Без передачи аргументов `.cache()` является синонимом `.persist(StorageLevel.MEMORY_ONLY)`. В этом случае нет никаких причин использовать один метод вместо другого. 

Доступные _уровни хранения_, определяемые в методе `.persist()`, перечислены ниже:
- `MEMORY_ONLY` -- это уровень по умолчанию. На нем сохраняется RDD, формирующий кадр данных, как десериализованные объекты Java в виртуальной машине JVM. Если RDD не умещается в памяти, то Spark не будет кешировать разделы, а при необходимости выполнит восстановительные вычисления. Пользователь об этом не уведомляется.
- `MEMORY_AND_DISK` -- аналогичен уровню `MEMORY_ONLY`, но когда Spark исчерпывает всю доступную память, он сериализует RDD на диск. Это медленее, так как диск более медленное устройство, но производительность будет различной в зависимости от класса хранилища на узле (например, NVM-накопители по сравнению с механическими накопителями).
- `MEMORY_ONLY_SER` -- аналогичен уровню `MEMORY_ONLY`, но объекты Java _сериализуются_. Это требует _меньшего пространства памяти_, но подготовка потребляет _больше процессорного времени_.
- `MEMORY_AND_DISK_SER` -- аналогичен уровню `MEMORY_AND_DISK`, но с сериализацией.
- `DISK_ONLY` -- на диск сохраняются разделы RDD, формирующие кадр данных.
- `OFF_HEAP` -- поведение аналогично уровню `MEMORY_ONLY_SER`, но здесь используется память вне кучи. Память вне кучи требует активизации.

Уровни `MEMORY_AND_DISK_2`, `MEMORY_AND_DISK_SER_2`, `MEMORY_ONLY_2` и `MEMORY_ONLY_SER_2` равнозначны уровням без суффикса `_2`, но добавляют _репликацию_ каждого раздела на двух узлах кластера. Эти уровни следует устанавливать, если необходима репликация данных с повышенной доступностью.

Можно использовать метод `.unpersist()` для _освобождения кеша_, а также метод `storageLevel()` для запроса текущего уровня кеширования кадра данных. Метод `.unpersist()` будет очищать кеш вне зависимости от того, создан ли кеш методом `.cache()` или `.persist()`. Кеш очищается, когда больше не требуется использование соответствующего кадра данных, и можно освободить память для обработки других наборов данных.

Если кадр данных не кеширован / не сохраняется, то метод `storageLevel()` возвращает значение `StorageLevel.NONE`. Если вы не освободили память, вручную, то она будет освобождена при завершении текущего сеанса, но в текущем сеансе эта память остается недоступной для других данных или для выполнения обработки.

### Механизм копирования данных в контрольных точках

Метод `.checkpoint()` выполняет усечение ориентированного ациклического графа (DAG) и _сохраняет_ содержимое кадра данных _на диск_. Содержимое кадра данных сохраняется в _каталог контрольных точек_. Для каталога контрольных точек не существует значений по умолчанию: они обязательно должны быть установлены с помощью метода `SparkContext` `setCheckPointDir()`. Если не установить каталог для контрольных точек, то в механизме сохранения данных в контрольных точках возникает критическая ошибка, и приложение прекращает выполнение.

Контрольная точка может быть _жадной_ (eager) или _ленивой_ (lazy). По умолчанию контрольная точка жадная и создается _немедленно_. Если на кадре данных вызвать метод `.checkpoint(eager=False)` то контрольная точка будет создана _только при вызове действия_. При создании жадной контрольной точки (немедленно) требуется время для предварительной подготовки, но после этого можно использовать кадр данных с контрольной точкой более эффективно.

Настроить пути, по которым будут сохраняться файлы контрольных точек, можно так
```python
with tempfile.TemporaryDirectory() as d:
	spark.sparkContext.setCheckPointDir("/tmp/bb")
	df.checkpoint(eager=False)
```

Следует отметить, что этот путь должен быть видимым из ==исполнителей==, а _не из драйвера_, так как именно _исполнитель_ будет выполнять операции сохранения данных в _контрольных точках на рабочем узле_, а ==не драйвер== [[Литература#^61ef72]]<c. 433>.

При создании экземпляра Spark-сесиии можно передать специальные параметры
```python
spark = SparkSession.builder \
    .appName("...") \
    .master("local[*]") \
    .config("spark.executor.memory", "70g") \
    .config("spark.driver.memory", "50g") \
    .config("spark.memory.offHeap.enabled", true) \
    .config("spark.memory.offHeap.size", "16g") \
    .getOrCreate()

with tempfile.TemporaryDirectory() as d:
    spark.sparkContext.setCheckPointDir("/tmp/bb")
    df.checkpoint(False)
...
```

Определяя размер памяти для драйвера (`spark.driver.memory`), следует иметь в виду, что если приложение запускается в локальном режиме, то драйвер уже работает, поэтому вы не сможете изменить размер его памяти [[Литература#^61ef72]]<c. 434>.

Необходимо всего помнить о следующих аспектах:
- даже если вы установили значения размеров памяти больше, чем реальный размер доступной памяти, виртуальная машина JVM не сможет использовать заявленную память,
- при работе в _локальном режиме_ вы _выполняете драйвер_, то есть ==не сможете изменить размер памяти==, выделенный драйверу после его запуска. Именно так работает виртуальная машина JVM. Но когда вы передаете `spark-submit` задание в кластер, Spark порождает ==новую виртуальную машину JVM==, а затем использует переданные параметры.

Кеш использует память. Данные в контрольных точках сохраняются в файлах. Кеш очищается при завершении сеанса (или раньше). Но данные, сохраненные в контрольных точках, никогда не удаляются и остаются на диске как файлы, сериализованные Java, то есть их можно без труда открыть. Нужно эти файлы удалить!

Метод `.collect()` (действие) возвращает содержимое кадров данных из всех исполнителей _драйверу_. 

Не существует абсолютного правила (например, сохранение данных в ленивых контрольных точках всегда лучше, чем кеширование): это всегда будет зависеть от конкретного набора данных, объема и среды выполнения.

Когда на кадре данных вызывается метод `.show()`, выполняется ==действие==, а не преобразование (см. [PySpark actions on dataframe](https://davy.ai/pyspark-actions-on-dataframe/#:~:text=When%20you%20execute%20the%20dataframe.show(),DataFrame%20in%20a%20tabular%20format)).

Множество проблем может возникать из-за разбалансировки данных: данные так фрагментированы по разделам, что операция соединения становится чрезвычайно долговременной. В этом случае может потребоваться исследование перераспределения данных по разделам с использованием функций `coalesce()`, `repartition()` или `repartitionByRange()`. Вероятнее всего, перераспределение данных по разделам окажется весьма затратной операцией, но она позволит повысить производительность в дальнейшем при выполнении соединений. 

Catalyst предпочитает работать с кадрами данных. Общеизвестно, что RDD обрабатываются медленнее, чем кадр данных.

_Разделы_ (partitions) не закреплены непосредственно за кадрами данных, они _связаны с RDD_ [[Литература#^61ef72]]<c. 465>. Следовательно, для доступа к разделам необходимо использовать метод `.rdd` кадра данных. Можно вызывать, например, метод `.getNumPartitions()` для получения количества разделов или даже метод `.getPartition()` для доступа к разделу.
