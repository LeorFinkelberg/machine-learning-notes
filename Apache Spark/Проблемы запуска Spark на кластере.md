Подробности можно найти здесь https://sparkbyexamples.com/spark/different-types-of-issues-while-running-spark-projects/ 
### Serialization Issues

Для того чтобы отправить объект по сети кластера Spark должен этот объект сериализовать. Если по какой-то причине объект сериализовать не получается, то получим такую ошибку
```bash
// Serialization Issues
org.apache.spark.SparkException: Task not serializable
```

Чтобы исправить ситуацию, можно попробовать что-то из приведенного в списке:
- Сделать кастомные классы _сериализуемыми_. Если есть кастомный класс на Spark/Scala нужно убедиться, что он использует `extends Serializable`. Сериализуемый объект преобразует свое состояние в поток байтов, чтобы его можно было передать по сети. Если работаем на Scala, то лучше использовать Case-классы, которые по умолчанию сериализуемы.
- Использовать `@transient`. Если нет необходимости транслировать объект на исполнителей, то его можно пометить аннотацией `@transient`. Любой объект, помеченный этой аннотацией будет игнорироваться при сериализации и не будет передаваться исполнителю.
- Использовать `Object`. Если работаем на Scala, то лучше использовать `Object`, они по умолчанию сериализуемы.

### Out of Memory Exceptions

Самая распространенная проблема при запуске Spark-приложения на кластере -- это `OutOfMemoryError`. Она может появляться либо на драйвере, либо на исполнителе.

Чтобы увеличить объем памяти на драйвере, используем следующие флаги
```bash
--driver-memory <XX>G
// (or)
--conf spark.driver.memory= <XX>G
```

А чтобы увеличить объем памяти на исполнителе, следующие
```bash
--executor-memory <XX>G
// (or)
--conf spark.executor.memory= <XX>G
```

### Optimizing Long Running Jobs

Прежде чем выкатывать приложение, нужно убедиться, что решение отрабатывает за приемлемое время. Если наблюдаются проблемы с производительностью, то следует попробовать следующее:
- кэшировать промежуточные результаты
- использовать broadcast-hash-join
- делать repartition на правильное число партиций
- уменьшить количество перетасовочных операций
- использовать Apache Parquet или Avro

### Broadcasting Large Data

Если выполняется транслирование (broadcasting) для broadcast-переменной или broadcast-join, нужно убедиться, что данные помещаются в памяти драйвера. В противном случае получим ошибку нехватки памяти.
```bash
--driver-memory <XX>G
// (or)
--conf spark.driver.memory= <XX>G
```