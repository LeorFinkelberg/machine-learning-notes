Иногда возникает необходимость соединить маленькую таблицу (сотни строк) с большой таблицей (миллионы строк). Чтобы сделать это эффективно, Spark предлагает функцию `.broadcast()`. Таблица меньшего размера транслируется на все рабочие узлы кластера. Это повышает производительность, так как Spark'у не требуется перетасовывать большую таблицу.
```python
df_large.join(F.broadcast(df_small), df_large["id"] == df_small["id"], "left_semi").count()
```