Подробности можно найти на странице https://scikit-learn.org/stable/auto_examples/model_selection/plot_roc.html#sphx-glr-auto-examples-model-selection-plot-roc-py.

NB! В задачах мультиклассовой классификации ==с сильным дисбалансом классов==, _микро-усреднение_ предпочтительнее макро-усреднения. Еще в качестве альтернативы можно использовать _взвешенное макро-усреднение_.
```
In a multi-class classification setup with highly imbalanced classes, micro-averaging is preferable over macro-averaging. In such cases, one can alternatively use a weighted macro-averaging, not demoed here.
```

Выдержка из документации Sklearn по $F_1$-score https://scikit-learn.org/stable/modules/generated/sklearn.metrics.f1_score.html.

Для задач _бинарной классификации_ по умолчанию используется бинарная стратегия усреднения `average="binary"`.

Для задач _мультиклассовой классификации_ есть несколько вариантов получить скалярную метрику (то есть поддерживаются различные стратегии усреднения):
- `micro` -- вычисляет метрики глобально, учитывая общее число истино-положительных, ложно-отрицательных и ложно-положительных экземпляров.
-  `macro` -- вычисляет метрики для каждой метки класса, а затем ищет их _невзвешенное среднее_.  ==Дисбаланс классов в случае макро-усреднения не учитывается==.
- `weighted` -- вычисляет метрики для каждой метки класса, а затем ищет их _взвешенное среднее по поддержке_ (число положительных экземпляров для каждой метки класса). _Взвешенное среднее учитывает дисбаланс классов!
- `samples` -- вычисляет метрики для каждого экземпляра, а затем ищет их среднее (имеет смысл только для задач классификации с мультиметками).

Таким образом, в задачах мультиклассовой классификации, гармоническое среднее (`f1_score(..., average="weighted")`, кажется адекватной метрикой качества.


